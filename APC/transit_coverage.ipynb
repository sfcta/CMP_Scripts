{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.167545Z",
     "start_time": "2021-10-27T00:08:23.754156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "from shapely.geometry import Point, Polygon, LineString, mapping\n",
    "from shapely import geometry\n",
    "from simpledbf import Dbf5\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.183545Z",
     "start_time": "2021-10-27T00:08:31.169545Z"
    }
   },
   "outputs": [],
   "source": [
    "# GTFS directories and service ids\n",
    "GTFS_May2021 = [r'C:\\Users\\xzh263\\Dropbox (KTC)\\SFCTA CMP\\2021 CMP\\APC\\gtfs_may13', '1_merged_10007724']\n",
    "GTFS_Apr2020 = [r'C:\\Users\\xzh263\\Dropbox (KTC)\\SFCTA CMP\\2021 CMP\\Coverage\\gtfs_2020april9', 1]\n",
    "GTFS_Oct2019 = [r'C:\\Users\\xzh263\\Dropbox (KTC)\\SFCTA CMP\\2021 CMP\\Coverage\\gtfs_2019oct9', '1_merged_9175740']\n",
    "\n",
    "# Output directory\n",
    "Coverage_Dir = r'C:\\Users\\xzh263\\Dropbox (KTC)\\SFCTA CMP\\2021 CMP\\Coverage'\n",
    "\n",
    "# OSM Streets\n",
    "Streets_Dir = r'C:\\Users\\xzh263\\Dropbox (KTC)\\SFCTA CMP\\2021 CMP\\Coverage\\champ_hwy_shapefile'\n",
    "street_file = 'champ_freeflow.shp'\n",
    "\n",
    "#TAZ shapefile\n",
    "TAZ_Dir = Coverage_Dir\n",
    "taz_file = 'TAZ2454_clean\\TAZ2454_clean.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SFCTA Paths\n",
    "\n",
    "# GTFS directories and service ids\n",
    "GTFS_May2021 = [r'Q:\\Data\\GTFS\\MUNI\\gtfs_2021may13', '1_merged_10007724']\n",
    "GTFS_Apr2020 = [r'Q:\\Data\\GTFS\\MUNI\\gtfs_2020april9', 1]\n",
    "GTFS_Oct2019 = [r'Q:\\Data\\GTFS\\MUNI\\gtfs_2019oct9', '1_merged_9175740']\n",
    "\n",
    "# Output directory\n",
    "Coverage_Dir = r'Q:\\CMP\\LOS Monitoring 2021\\Transit\\Coverage'\n",
    "\n",
    "# OSM Streets\n",
    "Streets_Dir = r'Q:\\CMP\\LOS Monitoring 2021\\Transit\\Coverage\\champ_hwy_shapefile'\n",
    "street_file = 'champ_freeflow.shp'\n",
    "\n",
    "#TAZ shapefile\n",
    "TAZ_Dir = Coverage_Dir\n",
    "taz_file = 'TAZ2454_clean\\TAZ2454_clean.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.199546Z",
     "start_time": "2021-10-27T00:08:31.186545Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define WGS 1984 coordinate system\n",
    "wgs84 = {'proj': 'longlat', 'ellps': 'WGS84', 'datum': 'WGS84', 'no_defs': True}\n",
    "\n",
    "#Define NAD 1983 StatePlane California III\n",
    "cal3 = {'proj': 'lcc +lat_1=37.06666666666667 +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000 +y_0=500000.0000000002', 'ellps': 'GRS80', 'datum': 'NAD83', 'no_defs': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.231548Z",
     "start_time": "2021-10-27T00:08:31.220548Z"
    }
   },
   "outputs": [],
   "source": [
    "day_threshold = 20\n",
    "hour_threshold = 10\n",
    "\n",
    "begin_hour = 7\n",
    "end_hour = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTFS Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.246550Z",
     "start_time": "2021-10-27T00:08:31.233548Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_transit_stops_geo(stop_dir):\n",
    "    stops=pd.read_csv(os.path.join(stop_dir, 'stops.txt'))\n",
    "    stops['geometry'] = list(zip(stops.stop_lon, stops.stop_lat))\n",
    "    stops['geometry'] = stops['geometry'].apply(Point)\n",
    "    stops = gp.GeoDataFrame(stops, geometry='geometry', crs={'init': 'epsg:4326'})\n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.262550Z",
     "start_time": "2021-10-27T00:08:31.249549Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_transit_shapes_geo(stop_dir, service_id):\n",
    "    shapes=pd.read_csv(os.path.join(stop_dir, 'shapes.txt'))\n",
    "    shapes_gdf = pd.DataFrame()\n",
    "    shape_ids = shapes.shape_id.unique().tolist()\n",
    "    rid = 0\n",
    "    for shpid in shape_ids:\n",
    "        shp = shapes[shapes['shape_id']==shpid].sort_values(by='shape_pt_sequence')\n",
    "        linestr = LineString(zip(shp.shape_pt_lon, shp.shape_pt_lat))\n",
    "        linestr = gp.GeoDataFrame(index=[shpid], crs='epsg:4326', geometry=[linestr]) \n",
    "        shapes_gdf = shapes_gdf.append(linestr)\n",
    "        rid = rid + 1\n",
    "    shapes_gdf = shapes_gdf.reset_index()\n",
    "    shapes_gdf.columns = ['shape_id', 'geometry']\n",
    "    \n",
    "    trips = pd.read_csv(os.path.join(stop_dir, 'trips.txt'))\n",
    "    trips = trips[trips['service_id']==service_id]\n",
    "    trips_shapes = shapes_gdf[shapes_gdf['shape_id'].isin(trips['shape_id'])]\n",
    "    return trips, shapes, trips_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:31.293552Z",
     "start_time": "2021-10-27T00:08:31.265552Z"
    }
   },
   "outputs": [],
   "source": [
    "def frequent_bus_routes(gtfs_dir, service_id, outname):\n",
    "    # input gtfs files\n",
    "    routes_info_cur=pd.read_csv(os.path.join(gtfs_dir, 'routes.txt'))\n",
    "    stops_cur = generate_transit_stops_geo(gtfs_dir)\n",
    "    trips_cur, shapes_cur, trips_shapes_cur = generate_transit_shapes_geo(gtfs_dir, service_id)\n",
    "    stop_times_cur = pd.read_csv(os.path.join(gtfs_dir, 'stop_times.txt'))\n",
    "    stop_times_cur['departure_hour'] = stop_times_cur['departure_time'].apply(lambda x: int(x[0:2]))\n",
    "    \n",
    "    #There may be multiples shapes for the same route, so here the most frequent shape is used for each route_id\n",
    "    trips_shapes_cur_mcv = trips_cur.groupby(['route_id', 'direction_id'])['shape_id'].agg(lambda x:x.value_counts().index[0]).reset_index()\n",
    "    \n",
    "    start_stops_idx = stop_times_cur.groupby(['trip_id'])['stop_sequence'].transform(min) == stop_times_cur['stop_sequence']\n",
    "    trips_cur_hour = pd.merge(trips_cur, \n",
    "                          stop_times_cur[start_stops_idx][['trip_id', 'arrival_time', 'departure_time', 'departure_hour']],\n",
    "                         on='trip_id', how='left')\n",
    "    \n",
    "    # trips occuring during the time period of interest\n",
    "    trips_cur_period = trips_cur_hour[(trips_cur_hour['departure_hour']>=begin_hour) & (trips_cur_hour['departure_hour']<end_hour)]\n",
    "\n",
    "    # total trips at least 225, hourly trips at least 10\n",
    "    route_period_counts = trips_cur_period.groupby(['route_id', 'direction_id']).trip_id.count().reset_index()\n",
    "    route_period_counts.columns = ['route_id', 'direction_id', 'total_trips']\n",
    "    route_frequent = route_period_counts[route_period_counts['total_trips']>= day_threshold]\n",
    "    \n",
    "    #hourly trips\n",
    "    route_hour = trips_cur_period.groupby(['route_id', 'direction_id', 'departure_hour']).trip_id.count().reset_index()\n",
    "    route_hour.columns = ['route_id', 'direction_id', 'hour', 'trips']\n",
    "    route_hour_counts = route_hour[route_hour['trips']>=hour_threshold].groupby(['route_id', 'direction_id']).hour.count().reset_index()\n",
    "    route_hour_counts.columns = ['route_id', 'direction_id', 'hour_count']\n",
    "    num_hours = end_hour - begin_hour\n",
    "    route_frequent = pd.merge(route_frequent, \n",
    "                              route_hour_counts[route_hour_counts['hour_count']==num_hours], \n",
    "                              on=['route_id', 'direction_id'])\n",
    "\n",
    "    route_frequent_shapes = route_frequent.merge(trips_shapes_cur_mcv, on=['route_id', 'direction_id'], how='left')\n",
    "    route_frequent_shapes = trips_shapes_cur.merge(route_frequent_shapes, on='shape_id')\n",
    "    route_frequent_shapes = route_frequent_shapes.merge(routes_info_cur, on='route_id', how='left')\n",
    "    #route_frequent_shapes.to_file(os.path.join(Coverage_Dir, 'route_frequent_5min_' + outname + '_from' + str(begin_hour) + 'to' + str(end_hour)+ '.shp'))\n",
    "    \n",
    "    \n",
    "    stop_times_by_route = stop_times_cur.merge(trips_cur[['route_id', 'direction_id', 'trip_id']], on='trip_id', how='left')\n",
    "    stop_times_by_route = stop_times_by_route[(stop_times_by_route['departure_hour']>=begin_hour) & (stop_times_by_route['departure_hour']<end_hour)]\n",
    "    \n",
    "    stop_period_counts = stop_times_by_route.groupby(['stop_id', 'route_id', 'direction_id']).trip_id.count().reset_index()\n",
    "    stop_period_counts.columns = ['stop_id', 'route_id', 'direction_id', 'total_trips']\n",
    "    stop_frequent = stop_period_counts[stop_period_counts['total_trips']>= day_threshold]\n",
    "    \n",
    "    stop_route_hour_count = stop_times_by_route.groupby(['stop_id', 'route_id', 'direction_id', 'departure_hour']).trip_id.count().reset_index()\n",
    "    stop_route_hour_count.columns = ['stop_id', 'route_id', 'direction_id', 'hour', 'trips']\n",
    "    stop_route_hour_count_frequent = stop_route_hour_count[stop_route_hour_count['trips']>=hour_threshold].groupby(['stop_id', 'route_id', 'direction_id']).hour.count().reset_index()\n",
    "    stop_route_hour_count_frequent.columns = ['stop_id', 'route_id', 'direction_id', 'hour_count']\n",
    "    \n",
    "    stop_frequent = pd.merge(stop_frequent, \n",
    "                          stop_route_hour_count_frequent[stop_route_hour_count_frequent['hour_count']==num_hours], \n",
    "                          on=['route_id', 'direction_id','stop_id'])\n",
    "    if len(stop_frequent)>0:\n",
    "        stop_frequent_list = stop_frequent.stop_id.unique().tolist()\n",
    "        stop_frequent_gdf = stops_cur[stops_cur['stop_id'].isin(stop_frequent_list)]\n",
    "        #stop_frequent_gdf.to_file(os.path.join(Coverage_Dir, 'route_frequent_5min_stops_' + outname + '_from' + str(begin_hour) + 'to' + str(end_hour)+ '.shp'))\n",
    "    else:\n",
    "        print('No frequent stops found!')\n",
    "        stop_frequent_list=[]\n",
    "    return stop_frequent_list, route_period_counts, stop_period_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:47.189390Z",
     "start_time": "2021-10-27T00:08:31.295554Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_frequent_list_2021may, route_period_counts_2021may, stop_period_counts_2021may = frequent_bus_routes(GTFS_May2021[0], GTFS_May2021[1], '2021may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:08:53.827735Z",
     "start_time": "2021-10-27T00:08:47.191387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frequent stops found!\n"
     ]
    }
   ],
   "source": [
    "stop_frequent_list_2020april, route_period_counts_2020april, stop_period_counts_2020april = frequent_bus_routes(GTFS_Apr2020[0], GTFS_Apr2020[1], '2020april')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:09:24.578349Z",
     "start_time": "2021-10-27T00:08:53.829738Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_frequent_list_2019oct, route_period_counts_2019oct, stop_period_counts_2019oct = frequent_bus_routes(GTFS_Oct2019[0], GTFS_Oct2019[1], '2019oct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAZ Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:09:41.011741Z",
     "start_time": "2021-10-27T00:09:24.580350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TAZs in SF 981\n"
     ]
    }
   ],
   "source": [
    "taz_shp = gp.read_file(os.path.join(TAZ_Dir, taz_file))\n",
    "taz_sf_shp = taz_shp[taz_shp['COUNTY']==1] \n",
    "print('Number of TAZs in SF', len(taz_sf_shp))\n",
    "taz_sf_shp = taz_sf_shp.to_crs(cal3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streets Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:12.327949Z",
     "start_time": "2021-10-27T00:09:41.014741Z"
    }
   },
   "outputs": [],
   "source": [
    "streets = gp.read_file(os.path.join(Streets_Dir, street_file))\n",
    "streets.insert(0, 'LinkID', range(1, len(streets)+1))\n",
    "streets = streets.to_crs(cal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:20.341346Z",
     "start_time": "2021-10-27T00:17:12.329949Z"
    }
   },
   "outputs": [],
   "source": [
    "def latlong(x):\n",
    "    return round(x.coords.xy[1][0],6), round(x.coords.xy[0][0], 6), round(x.coords.xy[1][-1], 6), round(x.coords.xy[0][-1], 6)\n",
    "streets['B_Lat'], streets['B_Long'], streets['E_Lat'], streets['E_Long'] = zip(*streets['geometry'].map(latlong))\n",
    "\n",
    "b_nodes = streets[['B_Lat', 'B_Long']]\n",
    "b_nodes.columns = ['Lat', 'Long']\n",
    "\n",
    "e_nodes = streets[['E_Lat', 'E_Long']]\n",
    "e_nodes.columns = ['Lat', 'Long']\n",
    "\n",
    "streets_endnodes = b_nodes.append(e_nodes, ignore_index=True).reset_index()\n",
    "\n",
    "# Assign unique node id\n",
    "endnodes_cnt=streets_endnodes.groupby(['Lat', 'Long']).index.count().reset_index()\n",
    "endnodes_cnt.rename(columns={'index':'NodeCnt'}, inplace=True)\n",
    "endnodes_cnt['NodeID'] = endnodes_cnt.index+1\n",
    "\n",
    "# Generate the the unique node shapefile  \n",
    "endnodes_cnt['geometry'] = list(zip(endnodes_cnt.Long, endnodes_cnt.Lat))\n",
    "endnodes_cnt['geometry'] = endnodes_cnt['geometry'].apply(Point)\n",
    "endnodes_unique_gpd = gp.GeoDataFrame(endnodes_cnt, geometry='geometry')\n",
    "endnodes_unique_gpd.crs = cal3\n",
    "endnodes_unique_gpd.to_file(os.path.join(Streets_Dir, 'streets_endnodes.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:20.515354Z",
     "start_time": "2021-10-27T00:17:20.343346Z"
    }
   },
   "outputs": [],
   "source": [
    "endnodes_cnt = endnodes_cnt[['Lat', 'Long', 'NodeCnt', 'NodeID']]\n",
    "endnodes_cnt.columns = ['B_Lat', 'B_Long', 'B_NodeCnt', 'B_NodeID']\n",
    "\n",
    "streets = streets.merge(endnodes_cnt, on=['B_Lat', 'B_Long'], how='left')\n",
    "\n",
    "endnodes_cnt.columns = ['E_Lat', 'E_Long', 'E_NodeCnt', 'E_NodeID']\n",
    "streets = streets.merge(endnodes_cnt, on=['E_Lat', 'E_Long'], how='left')\n",
    "\n",
    "endnodes_cnt.columns = ['Lat', 'Long', 'NodeCnt', 'NodeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:20.611359Z",
     "start_time": "2021-10-27T00:17:20.517354Z"
    }
   },
   "outputs": [],
   "source": [
    "streets['length'] = 3.2808 * streets.geometry.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:20.643360Z",
     "start_time": "2021-10-27T00:17:20.613360Z"
    }
   },
   "outputs": [],
   "source": [
    "streets['b_e'] = list(zip(streets['B_NodeID'], streets['E_NodeID']))\n",
    "streets['e_b'] = list(zip(streets['E_NodeID'], streets['B_NodeID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:17:20.689363Z",
     "start_time": "2021-10-27T00:17:20.646360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinkID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>TOLL</th>\n",
       "      <th>USE</th>\n",
       "      <th>CAP</th>\n",
       "      <th>AT</th>\n",
       "      <th>FT</th>\n",
       "      <th>STREETNAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>B_Long</th>\n",
       "      <th>E_Lat</th>\n",
       "      <th>E_Long</th>\n",
       "      <th>B_NodeCnt</th>\n",
       "      <th>B_NodeID</th>\n",
       "      <th>E_NodeCnt</th>\n",
       "      <th>E_NodeID</th>\n",
       "      <th>length</th>\n",
       "      <th>b_e</th>\n",
       "      <th>e_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6956</td>\n",
       "      <td>40029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>HWY 101 NORTHBOUND</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.832939e+06</td>\n",
       "      <td>635754.607976</td>\n",
       "      <td>1.832916e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>799.981191</td>\n",
       "      <td>(51, 111)</td>\n",
       "      <td>(111, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6985</td>\n",
       "      <td>52492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ALANA</td>\n",
       "      <td>WY</td>\n",
       "      <td>...</td>\n",
       "      <td>1.832827e+06</td>\n",
       "      <td>635823.487134</td>\n",
       "      <td>1.832810e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>547.801408</td>\n",
       "      <td>(82, 145)</td>\n",
       "      <td>(145, 82)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LinkID     A      B  TOLL  USE   CAP  AT  FT          STREETNAME  TYPE  \\\n",
       "0       1  6956  40029     0    1  1900   3   2  HWY 101 NORTHBOUND  None   \n",
       "1       2  6985  52492     0    1   700   3   4               ALANA    WY   \n",
       "\n",
       "   ...        B_Long          E_Lat        E_Long  B_NodeCnt  B_NodeID  \\\n",
       "0  ...  1.832939e+06  635754.607976  1.832916e+06          1        51   \n",
       "1  ...  1.832827e+06  635823.487134  1.832810e+06          2        82   \n",
       "\n",
       "   E_NodeCnt  E_NodeID      length        b_e        e_b  \n",
       "0          3       111  799.981191  (51, 111)  (111, 51)  \n",
       "1          4       145  547.801408  (82, 145)  (145, 82)  \n",
       "\n",
       "[2 rows x 65 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:18:13.810985Z",
     "start_time": "2021-10-27T00:17:20.691363Z"
    }
   },
   "outputs": [],
   "source": [
    "outcols = [c for c in streets.columns.tolist() if c not in ['b_e', 'e_b']]\n",
    "streets[outcols].to_file(os.path.join(Streets_Dir, 'streets_with_endnodes.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Walking Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:30:49.363108Z",
     "start_time": "2021-10-27T00:18:13.812987Z"
    }
   },
   "outputs": [],
   "source": [
    "stops_2021may = generate_transit_stops_geo(GTFS_May2021[0])\n",
    "stops_2021may = stops_2021may.to_crs(cal3)\n",
    "\n",
    "stops_2020april = generate_transit_stops_geo(GTFS_Apr2020[0])\n",
    "stops_2020april = stops_2020april.to_crs(cal3)\n",
    "\n",
    "stops_2019oct = generate_transit_stops_geo(GTFS_Oct2019[0])\n",
    "stops_2019oct = stops_2019oct.to_crs(cal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:30:49.379108Z",
     "start_time": "2021-10-27T00:30:49.366108Z"
    }
   },
   "outputs": [],
   "source": [
    "stops_2021may['stop_id'] = stops_2021may['stop_id'].astype(str)\n",
    "stops_2020april['stop_id'] = stops_2020april['stop_id'].astype(str)\n",
    "stops_2019oct['stop_id'] = stops_2019oct['stop_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:30:49.977136Z",
     "start_time": "2021-10-27T00:30:49.382111Z"
    }
   },
   "outputs": [],
   "source": [
    "stops_2021may_within_sf = gp.sjoin(stops_2021may, taz_sf_shp, op='within')\n",
    "stops_2020april_within_sf = gp.sjoin(stops_2020april, taz_sf_shp, op='within')\n",
    "stops_2019oct_within_sf = gp.sjoin(stops_2019oct, taz_sf_shp, op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:30:50.009137Z",
     "start_time": "2021-10-27T00:30:49.979136Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stops_2021may_within_sf.append(stops_2020april_within_sf, ignore_index=True)\n",
    "stops = stops.append(stops_2019oct_within_sf, ignore_index=True)\n",
    "stops = stops[stops_2021may.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T00:33:40.560793Z",
     "start_time": "2021-10-27T00:30:50.011138Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process took 78.4 seconds\n"
     ]
    }
   ],
   "source": [
    "stops_unique = stops.drop_duplicates(subset=['stop_id']).reset_index()\n",
    "\n",
    "# find the nearest street link and snap the transit stop on to the link\n",
    "\n",
    "stops_unique.insert(0, 'NodeID', range(endnodes_cnt['NodeID'].max() + 1, endnodes_cnt['NodeID'].max() + 1 + len(stops_unique)))\n",
    "import time\n",
    "start_time0=time.time()\n",
    "\n",
    "search_radius = 300 # ft\n",
    "\n",
    "stops_geo = stops_unique.copy()\n",
    "stops_geo['point_geo'] = stops_geo['geometry']\n",
    "stops_geo['geometry'] = stops_geo['geometry'].buffer(search_radius/3.2808)\n",
    "stop_near_links = gp.sjoin(streets[['LinkID', 'B_NodeID', 'E_NodeID', 'length', 'geometry']], stops_geo, op='intersects')\n",
    "\n",
    "def calc_dist(x):\n",
    "    stop_point = x['point_geo']\n",
    "    link_geo = x['geometry']\n",
    "    x['near_dist'] = stop_point.distance(link_geo)\n",
    "    x['stop_to_begin'] = link_geo.project(stop_point) * 3.2808  #meters to feet\n",
    "    x['stop_to_end'] = x['length'] - x['stop_to_begin']\n",
    "    return x\n",
    "\n",
    "stop_near_links = stop_near_links.apply(calc_dist, axis=1)\n",
    "stop_near_links = stop_near_links.sort_values(['stop_id','near_dist'])\n",
    "stop_near_links = stop_near_links.drop_duplicates('stop_id')\n",
    "stop_near_links['near_link'] = stop_near_links['LinkID']\n",
    "stop_near_links['near_link_bid'] = stop_near_links['B_NodeID']\n",
    "stop_near_links['near_link_eid'] = stop_near_links['E_NodeID']\n",
    "stop_near_links = stop_near_links.reset_index()\n",
    "stop_near_links['stop_id'] = stop_near_links['stop_id'].astype(str)\n",
    "print('Process took %s seconds' %(round(time.time() - start_time0, 1)))\n",
    "#stop_near_links.to_file(os.path.join(Coverage_Dir, 'transit_stops_nearest_links.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T23:20:01.440622Z",
     "start_time": "2021-10-26T23:20:00.395546Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct a network graph\n",
    "tgraph = nx.Graph() \n",
    "\n",
    "# road network nodes\n",
    "tgraph.add_nodes_from(endnodes_cnt.NodeID.tolist())\n",
    "\n",
    "# road network links\n",
    "for i in range (0, len(streets)):\n",
    "    tgraph.add_edge(streets.loc[i,'B_NodeID'], \n",
    "                          streets.loc[i,'E_NodeID'], \n",
    "                          weight = streets.loc[i, 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T23:56:30.560986Z",
     "start_time": "2021-10-11T23:56:30.551988Z"
    }
   },
   "outputs": [],
   "source": [
    "def walking_area(walk_graph, walk_dis, start_node, link_near_stop):\n",
    "    cur_path = dict(nx.single_source_dijkstra_path(walk_graph, start_node, cutoff=walk_dis, weight='weight'))\n",
    "    del cur_path[start_node]\n",
    "    reach_links = {}\n",
    "    for key in cur_path:\n",
    "        sub_path = list(zip(cur_path[key][:-1],cur_path[key][1:]))\n",
    "        for each_link in sub_path:\n",
    "            if each_link in reach_links:\n",
    "                next\n",
    "            else:\n",
    "                reach_links[each_link] = 1\n",
    "    reach_links_df = pd.DataFrame.from_dict(reach_links, orient='index',columns=['accessed']).reset_index()\n",
    "    reach_links_df.rename(columns={'index':'b_e'},inplace=True)\n",
    "    streets_access = streets[(streets['b_e'].isin(reach_links_df['b_e'])) | (streets['e_b'].isin(reach_links_df['b_e'])) | (streets['LinkID']==link_near_stop)]\n",
    "    geom = [x for x in streets_access.geometry]\n",
    "    multi_line = geometry.MultiLineString(geom)\n",
    "    multi_line_polygon = multi_line.convex_hull\n",
    "    \n",
    "    return multi_line_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T23:56:34.092608Z",
     "start_time": "2021-10-11T23:56:34.078642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accessible area from high frequent stops\n",
    "def frequent_access_area(stop_list, stop_with_nearest_link, buffer_radius):\n",
    "    start_time0=time.time()\n",
    "    stop_access_gdf = gp.GeoDataFrame()\n",
    "    cnt = 0\n",
    "    for cur_stop_id in stop_list:\n",
    "        if str(cur_stop_id) not in stop_with_nearest_link['stop_id'].to_list():\n",
    "            print('Warning: %s is not in the stops-nearest link dataset' %cur_stop_id)\n",
    "        else: \n",
    "            lidx = stop_with_nearest_link.index[stop_with_nearest_link['stop_id']==str(cur_stop_id)][0]\n",
    "            cur_node_id = stop_with_nearest_link.loc[lidx, 'NodeID']\n",
    "            cur_link = stop_with_nearest_link.loc[lidx, 'near_link']\n",
    "\n",
    "            cur_graph = tgraph.copy()\n",
    "            cur_graph.add_node(cur_node_id)\n",
    "            cur_graph.add_edge(stop_with_nearest_link.loc[lidx,'near_link_bid'], \n",
    "                              stop_with_nearest_link.loc[lidx,'NodeID'], \n",
    "                              weight = stop_with_nearest_link.loc[lidx, 'stop_to_begin'])\n",
    "            cur_graph.add_edge(stop_with_nearest_link.loc[lidx,'NodeID'], \n",
    "                                  stop_with_nearest_link.loc[lidx,'near_link_eid'], \n",
    "                                  weight = stop_with_nearest_link.loc[lidx, 'stop_to_end'])\n",
    "\n",
    "            get_geo = walking_area(cur_graph, buffer_radius, cur_node_id, cur_link)\n",
    "            cur_access_polygon = gp.GeoDataFrame(index=[0], crs=cal3, geometry=[get_geo])\n",
    "            stop_access_gdf = stop_access_gdf.append(cur_access_polygon, ignore_index=True)\n",
    "            cnt = cnt + 1\n",
    "            if cnt%500==0:\n",
    "                print('Processed %s Percent, took %s seconds'% ((round(100*cnt/len(stop_list),3)), round(time.time() - start_time0, 1)))\n",
    "    return stop_access_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T23:59:07.843507Z",
     "start_time": "2021-10-11T23:57:14.928711Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer_radius = 0.25 * 5280 # a quarter mile walking distance\n",
    "if len(stop_frequent_list_2021may) > 0:\n",
    "    frequent_stops_access_area_2021may = frequent_access_area(stop_frequent_list_2021may, stop_near_links, buffer_radius)\n",
    "    frequent_stops_access_union_2021may = frequent_stops_access_area_2021may.geometry.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:32:19.947951Z",
     "start_time": "2021-10-12T15:30:12.271156Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(stop_frequent_list_2020april) > 0:\n",
    "    frequent_stops_access_area_2020april = frequent_access_area(stop_frequent_list_2020april, stop_near_links, buffer_radius)\n",
    "    frequent_stops_access_union_2020april = frequent_stops_access_area_2020april.geometry.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:08:58.550468Z",
     "start_time": "2021-10-12T00:04:06.176888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 7522 is not in the stops-nearest link dataset\n"
     ]
    }
   ],
   "source": [
    "if len(stop_frequent_list_2019oct) > 0:\n",
    "    frequent_stops_access_area_2019oct = frequent_access_area(stop_frequent_list_2019oct, stop_near_links, buffer_radius)\n",
    "    frequent_stops_access_union_2019oct = frequent_stops_access_area_2019oct.geometry.unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach TAZ attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:09:12.302195Z",
     "start_time": "2021-10-12T00:09:12.114514Z"
    }
   },
   "outputs": [],
   "source": [
    "taz_dbf = Dbf5(os.path.join(Coverage_Dir, 'tazdata.dbf'))\n",
    "taz = taz_dbf.to_dataframe()\n",
    "taz['SFTAZ'] = taz['SFTAZ'].astype(int)\n",
    "taz_sf = taz_sf_shp.merge(taz, left_on = 'TAZ', right_on = 'SFTAZ', how = 'left')\n",
    "taz_sf[\"area_acre\"] = taz_sf['geometry'].area * 0.00024711 #Square meters to acres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:09:12.317195Z",
     "start_time": "2021-10-12T00:09:12.304195Z"
    }
   },
   "outputs": [],
   "source": [
    "def frequent_stops_access_taz(frequent_stops_access_union, outname):\n",
    "    frequent_stops_access_taz= taz_sf_shp['geometry'].intersection(frequent_stops_access_union)\n",
    "\n",
    "    taz_sf_access_gdf = gp.GeoDataFrame()\n",
    "    taz_sf_access_gdf['accessarea'] = frequent_stops_access_taz.area* 0.00024711 #Square meters to acres\n",
    "    taz_sf_access_gdf['index'] = frequent_stops_access_taz.index\n",
    "    taz_sf_access_gdf['geometry'] = frequent_stops_access_taz.geometry\n",
    "\n",
    "    taz_sf_access_tazid = taz_sf_access_gdf.merge(taz_sf_shp[['TAZ', 'AREALAND']], left_on='index', right_index=True, how='left')\n",
    "    taz_sf_access_attrs = taz_sf[['TAZ', 'AREALAND', 'HHLDS', 'TOTALEMP', 'POP', 'area_acre']].merge(taz_sf_access_tazid, on=['TAZ', 'AREALAND'], how='left')\n",
    "    \n",
    "    taz_sf_access_attrs['areapcnt'] = 100 * taz_sf_access_attrs['accessarea'] / taz_sf_access_attrs['area_acre']\n",
    "    taz_sf_access_attrs['access_pop'] = taz_sf_access_attrs['POP'] * taz_sf_access_attrs['areapcnt'] / 100 \n",
    "    taz_sf_access_attrs['access_jobs'] = taz_sf_access_attrs['TOTALEMP'] * taz_sf_access_attrs['areapcnt'] / 100 \n",
    "    taz_sf_access_attrs['access_hhlds'] = taz_sf_access_attrs['HHLDS'] * taz_sf_access_attrs['areapcnt'] / 100 \n",
    "    \n",
    "    outcols = ['accessarea', 'index', 'TAZ', 'AREALAND', 'HHLDS', 'TOTALEMP',\n",
    "           'POP', 'area_acre', 'areapcnt', 'access_pop', 'access_jobs', 'access_hhlds']\n",
    "    #taz_sf_access_attrs[outcols].to_csv(os.path.join(Coverage_Dir, 'frequent_stops_access_taz_intersect_' + outname+ '.csv'), index=False)\n",
    "    \n",
    "    return taz_sf_access_attrs[outcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:09:13.479252Z",
     "start_time": "2021-10-12T00:09:12.319196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage in 2021 May: \n",
      "Percentage of accessible area:  10.85\n",
      "Percentage of population:  21.81\n",
      "Percentage of jobs:  50.57\n",
      "Percentage of households:  25.01\n"
     ]
    }
   ],
   "source": [
    "if len(stop_frequent_list_2021may) > 0:\n",
    "    frequent_access_taz_attrs_2021may = frequent_stops_access_taz(frequent_stops_access_union_2021may, '2021may')\n",
    "\n",
    "    print('Coverage in 2021 May: ')\n",
    "    print('Percentage of accessible area: ', round(100*frequent_access_taz_attrs_2021may['accessarea'].sum()/frequent_access_taz_attrs_2021may['area_acre'].sum(),2))\n",
    "    print('Percentage of population: ', round(100*frequent_access_taz_attrs_2021may['access_pop'].sum()/frequent_access_taz_attrs_2021may['POP'].sum(),2))\n",
    "    print('Percentage of jobs: ', round(100*frequent_access_taz_attrs_2021may['access_jobs'].sum()/frequent_access_taz_attrs_2021may['TOTALEMP'].sum(),2))\n",
    "    print('Percentage of households: ', round(100*frequent_access_taz_attrs_2021may['access_hhlds'].sum()/frequent_access_taz_attrs_2021may['HHLDS'].sum(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:32:29.349997Z",
     "start_time": "2021-10-12T15:32:28.018369Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(stop_frequent_list_2020april) > 0:\n",
    "    frequent_access_taz_attrs_2020april = frequent_stops_access_taz(frequent_stops_access_union_2020april, '2020april')\n",
    "\n",
    "    print('Coverage in 2020 April: ')\n",
    "    print('Percentage of accessible area: ', round(100*frequent_access_taz_attrs_2020april['accessarea'].sum()/frequent_access_taz_attrs_2020april['area_acre'].sum(),2))\n",
    "    print('Percentage of population: ', round(100*frequent_access_taz_attrs_2020april['access_pop'].sum()/frequent_access_taz_attrs_2020april['POP'].sum(),2))\n",
    "    print('Percentage of jobs: ', round(100*frequent_access_taz_attrs_2020april['access_jobs'].sum()/frequent_access_taz_attrs_2020april['TOTALEMP'].sum(),2))\n",
    "    print('Percentage of households: ', round(100*frequent_access_taz_attrs_2020april['access_hhlds'].sum()/frequent_access_taz_attrs_2020april['HHLDS'].sum(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:32:41.209486Z",
     "start_time": "2021-10-12T15:32:40.054846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage in 2019 October: \n",
      "Percentage of accessible area:  13.07\n",
      "Percentage of population:  24.93\n",
      "Percentage of jobs:  47.54\n",
      "Percentage of households:  29.06\n"
     ]
    }
   ],
   "source": [
    "if len(stop_frequent_list_2019oct) > 0:\n",
    "    frequent_access_taz_attrs_2019oct = frequent_stops_access_taz(frequent_stops_access_union_2019oct, '2019oct')\n",
    "    print('Coverage in 2019 October: ')\n",
    "    print('Percentage of accessible area: ', round(100*frequent_access_taz_attrs_2019oct['accessarea'].sum()/frequent_access_taz_attrs_2019oct['area_acre'].sum(),2))\n",
    "    print('Percentage of population: ', round(100*frequent_access_taz_attrs_2019oct['access_pop'].sum()/frequent_access_taz_attrs_2019oct['POP'].sum(),2))\n",
    "    print('Percentage of jobs: ', round(100*frequent_access_taz_attrs_2019oct['access_jobs'].sum()/frequent_access_taz_attrs_2019oct['TOTALEMP'].sum(),2))\n",
    "    print('Percentage of households: ', round(100*frequent_access_taz_attrs_2019oct['access_hhlds'].sum()/frequent_access_taz_attrs_2019oct['HHLDS'].sum(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
